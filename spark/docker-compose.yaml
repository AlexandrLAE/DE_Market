services:
  spark-master:
    image: apache/spark:3.5.0
    container_name: spark-master
    hostname: spark-master
    command: >
      /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
      -h spark-master
      --port 7077
      --webui-port 8090
    ports:
      - "8090:8090"   # Web UI
      - "7077:7077"   # Spark Master URL
    environment:
      - SPARK_LOCAL_IP=spark-master
      - SPARK_PUBLIC_DNS=spark-master
      - SPARK_HADOOP_S3A_ENDPOINT=http://minio:9010
      - SPARK_HADOOP_S3A_ACCESS_KEY=${AWS_ACCESS_KEY_ID}
      - SPARK_HADOOP_S3A_SECRET_KEY=${AWS_SECRET_ACCESS_KEY}
      - SPARK_HADOOP_S3A_PATH_STYLE_ACCESS=true
      - SPARK_HADOOP_S3A_IMPL=org.apache.hadoop.fs.s3a.S3AFileSystem
      - SPARK_HADOOP_S3A_CONNECTION_SSL_ENABLED=false
    volumes:
      - ./data:/data
      - ./logs:/opt/spark/logs
    networks:
      - spark-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://spark-master:8090"]
      interval: 30s
      timeout: 10s
      retries: 3

  spark-worker-1:
    image: apache/spark:3.5.0
    container_name: spark-worker-1
    hostname: spark-worker-1
    command: >
      bash -c "sleep 10 && /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker
      spark://spark-master:7077
      --webui-port 8091
      -c 2
      -m 2G"
    depends_on:
      spark-master:
        condition: service_healthy
    ports:
      - "8091:8091"
    environment:
      - SPARK_LOCAL_IP=spark-worker-1
      - SPARK_PUBLIC_DNS=spark-worker-1
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2G
      - SPARK_HADOOP_S3A_ENDPOINT=http://minio:9010
      - SPARK_HADOOP_S3A_ACCESS_KEY=${AWS_ACCESS_KEY_ID}
      - SPARK_HADOOP_S3A_SECRET_KEY=${AWS_SECRET_ACCESS_KEY}
    volumes:
      - ./data:/data
      - ./logs:/opt/spark/logs
    networks:
      - spark-network
    restart: unless-stopped

networks:
  spark-network:
    driver: bridge